{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0: Install data\n",
    "\n",
    "Download from kaggle website. Create data folder with .gitignore file. Using Linux commands, change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 22.0M  100 22.0M    0     0  4344k      0  0:00:05  0:00:05 --:--:-- 5362k\n",
      "Archive:  ./data/mnist-dataset.zip\n",
      "  inflating: ./data/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte  \n",
      "  inflating: ./data/t10k-images.idx3-ubyte  \n",
      "  inflating: ./data/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte  \n",
      "  inflating: ./data/t10k-labels.idx1-ubyte  \n",
      "  inflating: ./data/train-images-idx3-ubyte/train-images-idx3-ubyte  \n",
      "  inflating: ./data/train-images.idx3-ubyte  \n",
      "  inflating: ./data/train-labels-idx1-ubyte/train-labels-idx1-ubyte  \n",
      "  inflating: ./data/train-labels.idx1-ubyte  \n"
     ]
    }
   ],
   "source": [
    "! mkdir data\n",
    "! echo data/ > .gitignore\n",
    "! curl -L -o ./data/mnist-dataset.zip https://www.kaggle.com/api/v1/datasets/download/hojjatk/mnist-dataset\n",
    "! unzip ./data/mnist-dataset.zip -d ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:17:20.085596Z",
     "iopub.status.busy": "2024-11-19T03:17:20.085246Z",
     "iopub.status.idle": "2024-11-19T03:17:20.661446Z",
     "shell.execute_reply": "2024-11-19T03:17:20.660325Z",
     "shell.execute_reply.started": "2024-11-19T03:17:20.085567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "import cv2\n",
    "import random\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images_path = 'data/train-images.idx3-ubyte'\n",
    "train_images_np = idx2numpy.convert_from_file(train_images_path)\n",
    "# train_images_np is now a np.ndarray type of object of shape (60000, 28, 28)\n",
    "\n",
    "train_labels_path = 'data/train-labels.idx1-ubyte'\n",
    "train_labels_np = idx2numpy.convert_from_file(train_labels_path)\n",
    "# train_labels_np is now a np.ndarray type of object of shape (60000, 1)\n",
    "\n",
    "t10k_images_path = 'data/t10k-images.idx3-ubyte'\n",
    "t10k_images_np = idx2numpy.convert_from_file(t10k_images_path)\n",
    "# t10k_images_np is now a np.ndarray type of object of shape (10000, 28, 28)\n",
    "\n",
    "t10k_labels_path = 'data/t10k-labels.idx1-ubyte'\n",
    "t10k_labels_np = idx2numpy.convert_from_file(t10k_labels_path)\n",
    "# t10k_labels_np is now a np.ndarray type of object of shape (10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:14:54.542588Z",
     "iopub.status.busy": "2024-11-19T03:14:54.542198Z",
     "iopub.status.idle": "2024-11-19T03:14:54.922228Z",
     "shell.execute_reply": "2024-11-19T03:14:54.920965Z",
     "shell.execute_reply.started": "2024-11-19T03:14:54.542554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only C and default locale supported with the posix collation implementation\n",
      "Only C and default locale supported with the posix collation implementation\n",
      "Case insensitive sorting unsupported in the posix collation implementation\n",
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    }
   ],
   "source": [
    "# press q to exit\n",
    "while True:\n",
    "    # Display the image using OpenCV\n",
    "    idx = random.randint(0, 59999)\n",
    "    cv2.imshow(f\"Value: {train_labels_np[idx]}\", train_images_np[idx])\n",
    "\n",
    "    # Wait for key press and check if 'q' is pressed (ASCII 113)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close the OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All images are made of 28x28 matrices with uint8 values, ranging 0 to 255.\n",
    "- All labels are uint8 values with the correspondent digit, ranging 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:16:51.898736Z",
     "iopub.status.busy": "2024-11-19T03:16:51.898342Z",
     "iopub.status.idle": "2024-11-19T03:16:51.906457Z",
     "shell.execute_reply": "2024-11-19T03:16:51.905233Z",
     "shell.execute_reply.started": "2024-11-19T03:16:51.898701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing with a Custom Dataset Class\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, train_images_np: np.ndarray, train_labels_np: np.ndarray):\n",
    "        self.images = train_images_np.astype(np.float32) / 255.0\n",
    "        self.labels = train_labels_np\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns two tensors, one 28x28 float32 with the image / 255.0 (0-1), one long (uint64) with the corresponding value (0-9)\n",
    "        \"\"\"\n",
    "        image = self.images[idx]#.reshape(28, 28)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Splitting Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Split\n",
    "train_images_set, val_images_set, train_labels_set, val_labels_set = train_test_split(train_images_np, train_labels_np, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = MNISTDataset(train_images_set, train_labels_set)\n",
    "val_dataset = MNISTDataset(val_images_set, val_labels_set)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Building the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:35:28.311719Z",
     "iopub.status.busy": "2024-11-19T03:35:28.310441Z",
     "iopub.status.idle": "2024-11-19T03:35:28.329877Z",
     "shell.execute_reply": "2024-11-19T03:35:28.328694Z",
     "shell.execute_reply.started": "2024-11-19T03:35:28.311677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the Neural Network Model\n",
    "input_layer = 784\n",
    "hidden_layer1 = 128\n",
    "hidden_layer2 = 64\n",
    "output_layer = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_layer, hidden_layer1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer1, hidden_layer2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer2, output_layer)\n",
    ")\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    \"\"\"Trains the neural network and evaluates it on validation data.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.view(images.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(images)\n",
    "            loss = loss_function(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Validation Step\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.view(images.size(0), -1)\n",
    "                predictions = model(images)\n",
    "                val_loss += loss_function(predictions, labels).item()\n",
    "                correct += (predictions.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        # Print Epoch Metrics\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"Validation Accuracy: {100 * correct / len(val_dataset):.2f}%\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:18:29.961033Z",
     "iopub.status.busy": "2024-11-19T03:18:29.960614Z",
     "iopub.status.idle": "2024-11-19T03:18:54.800035Z",
     "shell.execute_reply": "2024-11-19T03:18:54.798914Z",
     "shell.execute_reply.started": "2024-11-19T03:18:29.960995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.3833\n",
      "Validation Loss: 0.2094\n",
      "Validation Accuracy: 93.80%\n",
      "------------------------------\n",
      "Epoch 2/10\n",
      "Train Loss: 0.1665\n",
      "Validation Loss: 0.1379\n",
      "Validation Accuracy: 95.84%\n",
      "------------------------------\n",
      "Epoch 3/10\n",
      "Train Loss: 0.1139\n",
      "Validation Loss: 0.1331\n",
      "Validation Accuracy: 95.97%\n",
      "------------------------------\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0857\n",
      "Validation Loss: 0.1042\n",
      "Validation Accuracy: 96.77%\n",
      "------------------------------\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0659\n",
      "Validation Loss: 0.1028\n",
      "Validation Accuracy: 96.88%\n",
      "------------------------------\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0543\n",
      "Validation Loss: 0.0833\n",
      "Validation Accuracy: 97.53%\n",
      "------------------------------\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0426\n",
      "Validation Loss: 0.0884\n",
      "Validation Accuracy: 97.51%\n",
      "------------------------------\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0342\n",
      "Validation Loss: 0.0838\n",
      "Validation Accuracy: 97.74%\n",
      "------------------------------\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0290\n",
      "Validation Loss: 0.0958\n",
      "Validation Accuracy: 97.37%\n",
      "------------------------------\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0233\n",
      "Validation Loss: 0.0977\n",
      "Validation Accuracy: 97.35%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Preprocessing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10k_images_path = 'data/t10k-images.idx3-ubyte'\n",
    "t10k_images_np = idx2numpy.convert_from_file(t10k_images_path)\n",
    "# t10k_images_np is now a np.ndarray type of object of shape (10000, 28, 28)\n",
    "\n",
    "t10k_labels_path = 'data/t10k-labels.idx1-ubyte'\n",
    "t10k_labels_np = idx2numpy.convert_from_file(t10k_labels_path)\n",
    "# t10k_labels_np is now a np.ndarray type of object of shape (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:23:44.603910Z",
     "iopub.status.busy": "2024-11-19T03:23:44.603526Z",
     "iopub.status.idle": "2024-11-19T03:23:44.669729Z",
     "shell.execute_reply": "2024-11-19T03:23:44.668566Z",
     "shell.execute_reply.started": "2024-11-19T03:23:44.603857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = MNISTDataset(t10k_images_np, t10k_labels_np)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9: Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T03:23:53.344832Z",
     "iopub.status.busy": "2024-11-19T03:23:53.343889Z",
     "iopub.status.idle": "2024-11-19T03:23:53.350517Z",
     "shell.execute_reply": "2024-11-19T03:23:53.349342Z",
     "shell.execute_reply.started": "2024-11-19T03:23:53.344791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# press q to exit\n",
    "while True:\n",
    "    # Display the image using OpenCV\n",
    "    idx = random.randint(0, 9999)\n",
    "    \n",
    "    # Display the image using OpenCV\n",
    "    test_dataset = MNISTDataset(np.expand_dims(t10k_images_np[idx], axis=0), np.expand_dims(t10k_labels_np[idx], axis=0))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    for image, label in test_loader: # for each item in batch_size\n",
    "        image = image.view(image.size(0), -1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            predicted_label = outputs.argmax(1).tolist()[0]\n",
    "    \n",
    "    printable_label = label.numpy()[0]\n",
    "    printable_predicted_label = predicted_label\n",
    "    printable_image = image.view(image.size(0), 1, 28, 28).numpy()[0][0]\n",
    "    # print(printable_label, printable_predicted_label, printable_image.shape)\n",
    "    #break\n",
    "    cv2.imshow(f\"True Value: {printable_label}, Predicted Value: {printable_predicted_label}\", printable_image)\n",
    "    # Wait for key press and check if 'q' is pressed (ASCII 113)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close the OpenCV window\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mnist-complete-n6dHHUNe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
